2019-12-18 15:49:04 ===> -------------------------------------------This is all configurations-----------------------------------------
2019-12-18 15:49:04 ===> opts:
user=zjf,
experiment=Unet_3D_,
data=2019-12-18,
warm=30,
root=/data1/zjf,
train_dir=MICCAI_BraTS_2019_Data_Training,
valid_dir=MICCAI_BraTS_2019_Data_Validation,
mode=train_all,
train_file=train_small.txt,
valid_file=valid_small.txt,
dataset=brats,
model=resnet,
model_name=Unet_3D,
model_depth=34,
input_C=4,
input_H=240,
input_W=240,
input_D=160,
output_D=155,
resnet_shortcut=A,
lr=0.001,
weight_decay=1e-05,
amsgrad=True,
criterion=softmax_dice,
num_class=4,
description=Unet_3d training on 128!,
seed=1,
no_cuda=False,
resume=checkpoint/DMFNet_T128_xavier_2019-11-19/model_epoch_139.pth,
load=False,
valid_transform=Compose([Pad((0, 0, 0, 5, 0)),NumpyType((np.float32, np.int64))]),
GPU=4, 5, 6, 7,
num_workers=8,
batch_size=4,
start_epoch=0,
end_epoch=500,
save_freq=50,
output_dir=output,
submission=submission,
visual=visualization,
test_date=2019-12-14,
test_file=model_epoch_last.pth,
snapshot=True,
use_TTA=False,
post_process=True,
save_format=nii,
crop_H=128,
crop_W=128,
crop_D=128
2019-12-18 15:49:04 ===> ---------------------------------------------This is a halving line-------------------------------------------
2019-12-18 15:49:04 ===> Unet_3d training on 128!
2019-12-18 15:49:10 ===> re-training!!!
2019-12-18 15:49:10 ===> Samples for train = 80
2019-12-18 15:50:17 ===> Epoch: 0_Iter:0  loss: 2.95075 || 1:0.0226 | 2:0.0200 | 4:0.0066 ||
2019-12-18 15:50:22 ===> Epoch: 0_Iter:1  loss: 2.82050 || 1:0.0512 | 2:0.1210 | 4:0.0074 ||
2019-12-18 15:50:23 ===> Epoch: 0_Iter:2  loss: 2.86288 || 1:0.0088 | 2:0.1260 | 4:0.0023 ||
2019-12-18 15:50:24 ===> Epoch: 0_Iter:3  loss: 2.91457 || 1:0.0054 | 2:0.0783 | 4:0.0017 ||
2019-12-18 15:50:24 ===> Epoch: 0_Iter:4  loss: 2.88913 || 1:0.0248 | 2:0.0860 | 4:0.0000 ||
2019-12-18 15:50:25 ===> Epoch: 0_Iter:5  loss: 2.82327 || 1:0.0810 | 2:0.0935 | 4:0.0022 ||
2019-12-18 15:50:26 ===> Epoch: 0_Iter:6  loss: 2.92374 || 1:0.0362 | 2:0.0401 | 4:0.0000 ||
2019-12-18 15:50:27 ===> Epoch: 0_Iter:7  loss: 2.85622 || 1:0.0489 | 2:0.0937 | 4:0.0012 ||
2019-12-18 15:50:38 ===> Epoch: 0_Iter:8  loss: 2.81439 || 1:0.0491 | 2:0.1358 | 4:0.0007 ||
2019-12-18 15:50:40 ===> Epoch: 0_Iter:9  loss: 2.72575 || 1:0.0364 | 2:0.2356 | 4:0.0022 ||
2019-12-18 15:50:40 ===> Epoch: 0_Iter:10  loss: 2.80877 || 1:0.0281 | 2:0.1615 | 4:0.0016 ||
2019-12-18 15:50:41 ===> Epoch: 0_Iter:11  loss: 2.81917 || 1:0.0133 | 2:0.1638 | 4:0.0038 ||
2019-12-18 15:50:42 ===> Epoch: 0_Iter:12  loss: 2.79080 || 1:0.0676 | 2:0.1367 | 4:0.0049 ||
2019-12-18 15:50:42 ===> Epoch: 0_Iter:13  loss: 2.81283 || 1:0.0205 | 2:0.1654 | 4:0.0012 ||
2019-12-18 15:50:43 ===> Epoch: 0_Iter:14  loss: 2.76225 || 1:0.0642 | 2:0.1730 | 4:0.0005 ||
2019-12-18 15:50:44 ===> Epoch: 0_Iter:15  loss: 2.80963 || 1:0.0215 | 2:0.1678 | 4:0.0010 ||
2019-12-18 15:51:21 ===> Epoch: 0_Iter:16  loss: 2.82237 || 1:0.0182 | 2:0.1415 | 4:0.0179 ||
2019-12-18 15:51:23 ===> Epoch: 0_Iter:17  loss: 2.81870 || 1:0.0252 | 2:0.1530 | 4:0.0031 ||
2019-12-18 15:51:24 ===> Epoch: 0_Iter:18  loss: 2.82760 || 1:0.0174 | 2:0.1541 | 4:0.0010 ||
2019-12-18 15:51:25 ===> Epoch: 0_Iter:19  loss: 2.86967 || 1:0.0815 | 2:0.0489 | 4:0.0000 ||
2019-12-18 15:51:25 ===> Current epoch time consumption: 2.26 minutes!
2019-12-18 15:51:25 ===> Estimated remaining training time: 18.81 hours!
2019-12-18 15:52:06 ===> -------------------------------------------This is all configurations-----------------------------------------
2019-12-18 15:52:06 ===> opts:
user=zjf,
experiment=Unet_3D_,
data=2019-12-18,
warm=30,
root=/data1/zjf,
train_dir=MICCAI_BraTS_2019_Data_Training,
valid_dir=MICCAI_BraTS_2019_Data_Validation,
mode=train_all,
train_file=train_small.txt,
valid_file=valid_small.txt,
dataset=brats,
model=resnet,
model_name=Unet_3D,
model_depth=34,
input_C=4,
input_H=240,
input_W=240,
input_D=160,
output_D=155,
resnet_shortcut=A,
lr=0.001,
weight_decay=1e-05,
amsgrad=True,
criterion=softmax_dice,
num_class=4,
description=Unet_3d training on 128!,
seed=5,
no_cuda=False,
resume=checkpoint/DMFNet_T128_xavier_2019-11-19/model_epoch_139.pth,
load=False,
valid_transform=Compose([Pad((0, 0, 0, 5, 0)),NumpyType((np.float32, np.int64))]),
GPU=4, 5, 6, 7,
num_workers=8,
batch_size=4,
start_epoch=0,
end_epoch=500,
save_freq=50,
output_dir=output,
submission=submission,
visual=visualization,
test_date=2019-12-14,
test_file=model_epoch_last.pth,
snapshot=True,
use_TTA=False,
post_process=True,
save_format=nii,
crop_H=128,
crop_W=128,
crop_D=128
2019-12-18 15:52:06 ===> ---------------------------------------------This is a halving line-------------------------------------------
2019-12-18 15:52:06 ===> Unet_3d training on 128!
2019-12-18 15:52:11 ===> re-training!!!
2019-12-18 15:52:11 ===> Samples for train = 80
2019-12-18 15:53:19 ===> Epoch: 0_Iter:0  loss: 2.93094 || 1:0.0222 | 2:0.0340 | 4:0.0129 ||
2019-12-18 15:53:26 ===> Epoch: 0_Iter:1  loss: 2.93025 || 1:0.0105 | 2:0.0483 | 4:0.0109 ||
2019-12-18 15:53:27 ===> Epoch: 0_Iter:2  loss: 2.90557 || 1:0.0128 | 2:0.0498 | 4:0.0318 ||
2019-12-18 15:53:27 ===> Epoch: 0_Iter:3  loss: 2.98284 || 1:0.0051 | 2:0.0109 | 4:0.0012 ||
2019-12-18 15:53:28 ===> Epoch: 0_Iter:4  loss: 2.92820 || 1:0.0176 | 2:0.0454 | 4:0.0087 ||
2019-12-18 15:53:29 ===> Epoch: 0_Iter:5  loss: 2.87309 || 1:0.0143 | 2:0.0906 | 4:0.0220 ||
2019-12-18 15:53:29 ===> Epoch: 0_Iter:6  loss: 2.80308 || 1:0.1013 | 2:0.0948 | 4:0.0008 ||
2019-12-18 15:53:30 ===> Epoch: 0_Iter:7  loss: 2.85428 || 1:0.0816 | 2:0.0505 | 4:0.0135 ||
2019-12-18 15:53:41 ===> Epoch: 0_Iter:8  loss: 2.80993 || 1:0.0520 | 2:0.1160 | 4:0.0221 ||
2019-12-18 15:53:41 ===> Epoch: 0_Iter:9  loss: 2.75445 || 1:0.0537 | 2:0.1816 | 4:0.0102 ||
2019-12-18 15:53:42 ===> Epoch: 0_Iter:10  loss: 2.84767 || 1:0.0096 | 2:0.0972 | 4:0.0455 ||
2019-12-18 15:53:43 ===> Epoch: 0_Iter:11  loss: 2.83410 || 1:0.0646 | 2:0.0956 | 4:0.0056 ||
2019-12-18 15:53:43 ===> Epoch: 0_Iter:12  loss: 2.86778 || 1:0.0740 | 2:0.0565 | 4:0.0017 ||
2019-12-18 15:53:44 ===> Epoch: 0_Iter:13  loss: 2.71363 || 1:0.1486 | 2:0.0985 | 4:0.0393 ||
2019-12-18 15:53:45 ===> Epoch: 0_Iter:14  loss: 2.76754 || 1:0.0366 | 2:0.1209 | 4:0.0750 ||
2019-12-18 15:53:45 ===> Epoch: 0_Iter:15  loss: 2.69041 || 1:0.1166 | 2:0.1555 | 4:0.0375 ||
2019-12-18 15:54:23 ===> Epoch: 0_Iter:16  loss: 2.62793 || 1:0.1403 | 2:0.2025 | 4:0.0293 ||
2019-12-18 15:54:24 ===> Epoch: 0_Iter:17  loss: 2.78349 || 1:0.0123 | 2:0.1899 | 4:0.0143 ||
2019-12-18 15:54:24 ===> Epoch: 0_Iter:18  loss: 2.83544 || 1:0.0273 | 2:0.1069 | 4:0.0303 ||
2019-12-18 15:54:27 ===> Epoch: 0_Iter:19  loss: 2.90371 || 1:0.0204 | 2:0.0717 | 4:0.0042 ||
2019-12-18 15:54:28 ===> Current epoch time consumption: 2.27 minutes!
2019-12-18 15:54:28 ===> Estimated remaining training time: 18.91 hours!
2019-12-18 15:55:14 ===> Epoch: 1_Iter:0  loss: 2.81165 || 1:0.0339 | 2:0.1226 | 4:0.0319 ||
2019-12-18 15:55:15 ===> Epoch: 1_Iter:1  loss: 2.70787 || 1:0.1425 | 2:0.1398 | 4:0.0099 ||
2019-12-18 15:55:16 ===> Epoch: 1_Iter:2  loss: 2.87521 || 1:0.0084 | 2:0.1098 | 4:0.0066 ||
2019-12-18 15:55:16 ===> Epoch: 1_Iter:3  loss: 2.78118 || 1:0.0102 | 2:0.1889 | 4:0.0197 ||
2019-12-18 15:55:17 ===> Epoch: 1_Iter:4  loss: 2.85804 || 1:0.0803 | 2:0.0588 | 4:0.0028 ||
2019-12-18 15:55:18 ===> Epoch: 1_Iter:5  loss: 2.71113 || 1:0.0457 | 2:0.2246 | 4:0.0185 ||
2019-12-18 15:55:18 ===> Epoch: 1_Iter:6  loss: 2.75651 || 1:0.0202 | 2:0.1861 | 4:0.0372 ||
2019-12-18 15:55:19 ===> Epoch: 1_Iter:7  loss: 2.69119 || 1:0.0926 | 2:0.1903 | 4:0.0258 ||
2019-12-18 15:55:58 ===> Epoch: 1_Iter:8  loss: 2.77805 || 1:0.0172 | 2:0.1586 | 4:0.0462 ||
2019-12-18 15:55:59 ===> Epoch: 1_Iter:9  loss: 2.72451 || 1:0.0798 | 2:0.1789 | 4:0.0168 ||
2019-12-18 15:56:00 ===> Epoch: 1_Iter:10  loss: 2.69305 || 1:0.0108 | 2:0.2166 | 4:0.0796 ||
2019-12-18 15:56:02 ===> Epoch: 1_Iter:11  loss: 2.79878 || 1:0.0359 | 2:0.1485 | 4:0.0168 ||
2019-12-18 15:56:03 ===> Epoch: 1_Iter:12  loss: 2.68493 || 1:0.0122 | 2:0.2423 | 4:0.0606 ||
2019-12-18 15:56:03 ===> Epoch: 1_Iter:13  loss: 2.87350 || 1:0.0021 | 2:0.1173 | 4:0.0071 ||
2019-12-18 15:56:04 ===> Epoch: 1_Iter:14  loss: 2.77408 || 1:0.0406 | 2:0.1477 | 4:0.0376 ||
2019-12-18 15:56:05 ===> Epoch: 1_Iter:15  loss: 2.72169 || 1:0.0907 | 2:0.1718 | 4:0.0159 ||
2019-12-18 15:56:41 ===> Epoch: 1_Iter:16  loss: 2.80848 || 1:0.0457 | 2:0.1165 | 4:0.0294 ||
2019-12-18 15:56:42 ===> Epoch: 1_Iter:17  loss: 2.75562 || 1:0.0335 | 2:0.1786 | 4:0.0323 ||
2019-12-18 15:56:43 ===> Epoch: 1_Iter:18  loss: 2.68249 || 1:0.0208 | 2:0.2511 | 4:0.0456 ||
2019-12-18 15:56:45 ===> Epoch: 1_Iter:19  loss: 2.86595 || 1:0.0117 | 2:0.1129 | 4:0.0095 ||
2019-12-18 15:56:46 ===> Current epoch time consumption: 2.31 minutes!
2019-12-18 15:56:46 ===> Estimated remaining training time: 19.14 hours!
2019-12-18 15:57:33 ===> Epoch: 2_Iter:0  loss: 2.86282 || 1:0.0643 | 2:0.0696 | 4:0.0033 ||
2019-12-18 15:57:34 ===> Epoch: 2_Iter:1  loss: 2.71648 || 1:0.0181 | 2:0.2355 | 4:0.0299 ||
2019-12-18 15:57:35 ===> Epoch: 2_Iter:2  loss: 2.73390 || 1:0.0195 | 2:0.1868 | 4:0.0598 ||
2019-12-18 15:57:35 ===> Epoch: 2_Iter:3  loss: 2.79243 || 1:0.0286 | 2:0.1407 | 4:0.0383 ||
2019-12-18 15:57:36 ===> Epoch: 2_Iter:4  loss: 2.71076 || 1:0.0341 | 2:0.2379 | 4:0.0173 ||
2019-12-18 15:57:37 ===> Epoch: 2_Iter:5  loss: 2.84035 || 1:0.0147 | 2:0.1369 | 4:0.0080 ||
2019-12-18 15:57:37 ===> Epoch: 2_Iter:6  loss: 2.71408 || 1:0.0710 | 2:0.2092 | 4:0.0056 ||
2019-12-18 15:57:38 ===> Epoch: 2_Iter:7  loss: 2.75793 || 1:0.0051 | 2:0.1926 | 4:0.0444 ||
2019-12-18 15:58:17 ===> Epoch: 2_Iter:8  loss: 2.75368 || 1:0.0196 | 2:0.2091 | 4:0.0177 ||
2019-12-18 15:58:18 ===> Epoch: 2_Iter:9  loss: 2.78158 || 1:0.0066 | 2:0.1964 | 4:0.0154 ||
2019-12-18 15:58:18 ===> Epoch: 2_Iter:10  loss: 2.77384 || 1:0.0344 | 2:0.1729 | 4:0.0189 ||
2019-12-18 15:58:19 ===> Epoch: 2_Iter:11  loss: 2.91527 || 1:0.0112 | 2:0.0637 | 4:0.0098 ||
2019-12-18 15:58:20 ===> Epoch: 2_Iter:12  loss: 2.88756 || 1:0.0292 | 2:0.0627 | 4:0.0205 ||
2019-12-18 15:58:20 ===> Epoch: 2_Iter:13  loss: 2.75467 || 1:0.0241 | 2:0.1899 | 4:0.0313 ||
2019-12-18 15:58:21 ===> Epoch: 2_Iter:14  loss: 2.76195 || 1:0.0700 | 2:0.1468 | 4:0.0212 ||
2019-12-18 15:58:22 ===> Epoch: 2_Iter:15  loss: 2.88892 || 1:0.0302 | 2:0.0792 | 4:0.0017 ||
2019-12-18 15:59:00 ===> Epoch: 2_Iter:16  loss: 2.80891 || 1:0.0361 | 2:0.1322 | 4:0.0228 ||
2019-12-18 15:59:01 ===> Epoch: 2_Iter:17  loss: 2.80203 || 1:0.0724 | 2:0.1245 | 4:0.0011 ||
2019-12-18 15:59:01 ===> Epoch: 2_Iter:18  loss: 2.79563 || 1:0.0330 | 2:0.1606 | 4:0.0109 ||
2019-12-18 15:59:02 ===> Epoch: 2_Iter:19  loss: 2.82304 || 1:0.0073 | 2:0.1216 | 4:0.0480 ||
2019-12-18 15:59:03 ===> Current epoch time consumption: 2.28 minutes!
2019-12-18 15:59:03 ===> Estimated remaining training time: 18.92 hours!
2019-12-18 15:59:52 ===> Epoch: 3_Iter:0  loss: 2.73931 || 1:0.0311 | 2:0.1931 | 4:0.0365 ||
2019-12-18 15:59:52 ===> Epoch: 3_Iter:1  loss: 2.84808 || 1:0.0992 | 2:0.0520 | 4:0.0006 ||
2019-12-18 15:59:53 ===> Epoch: 3_Iter:2  loss: 2.87304 || 1:0.0787 | 2:0.0467 | 4:0.0015 ||
2019-12-18 15:59:54 ===> Epoch: 3_Iter:3  loss: 2.72797 || 1:0.0452 | 2:0.1763 | 4:0.0505 ||
2019-12-18 15:59:54 ===> Epoch: 3_Iter:4  loss: 2.79708 || 1:0.0432 | 2:0.1326 | 4:0.0272 ||
2019-12-18 15:59:55 ===> Epoch: 3_Iter:5  loss: 2.78686 || 1:0.1109 | 2:0.0876 | 4:0.0147 ||
2019-12-18 15:59:56 ===> Epoch: 3_Iter:6  loss: 2.70513 || 1:0.1633 | 2:0.1251 | 4:0.0065 ||
2019-12-18 15:59:57 ===> Epoch: 3_Iter:7  loss: 2.81460 || 1:0.0310 | 2:0.1381 | 4:0.0163 ||
2019-12-18 16:00:37 ===> Epoch: 3_Iter:8  loss: 2.96194 || 1:0.0006 | 2:0.0353 | 4:0.0022 ||
2019-12-18 16:00:37 ===> Epoch: 3_Iter:9  loss: 2.78752 || 1:0.0388 | 2:0.1484 | 4:0.0253 ||
2019-12-18 16:00:38 ===> Epoch: 3_Iter:10  loss: 2.67489 || 1:0.0851 | 2:0.2136 | 4:0.0264 ||
2019-12-18 16:00:39 ===> Epoch: 3_Iter:11  loss: 2.76621 || 1:0.0058 | 2:0.1954 | 4:0.0326 ||
2019-12-18 16:00:39 ===> Epoch: 3_Iter:12  loss: 2.66403 || 1:0.1172 | 2:0.1992 | 4:0.0196 ||
2019-12-18 16:00:40 ===> Epoch: 3_Iter:13  loss: 2.70584 || 1:0.0363 | 2:0.2237 | 4:0.0342 ||
2019-12-18 16:00:41 ===> Epoch: 3_Iter:14  loss: 2.79366 || 1:0.1113 | 2:0.0795 | 4:0.0155 ||
2019-12-18 16:00:41 ===> Epoch: 3_Iter:15  loss: 2.85643 || 1:0.0212 | 2:0.1103 | 4:0.0121 ||
2019-12-18 16:01:20 ===> Epoch: 3_Iter:16  loss: 2.76074 || 1:0.0061 | 2:0.2150 | 4:0.0182 ||
2019-12-18 16:01:21 ===> Epoch: 3_Iter:17  loss: 2.73940 || 1:0.0068 | 2:0.2359 | 4:0.0178 ||
2019-12-18 16:01:21 ===> Epoch: 3_Iter:18  loss: 2.87610 || 1:0.0055 | 2:0.0949 | 4:0.0235 ||
2019-12-18 16:01:22 ===> Epoch: 3_Iter:19  loss: 2.81196 || 1:0.0437 | 2:0.1377 | 4:0.0066 ||
2019-12-18 16:01:23 ===> Current epoch time consumption: 2.33 minutes!
2019-12-18 16:01:23 ===> Estimated remaining training time: 19.26 hours!
2019-12-18 16:02:09 ===> Epoch: 4_Iter:0  loss: 2.81411 || 1:0.0422 | 2:0.1141 | 4:0.0296 ||
2019-12-18 16:02:10 ===> Epoch: 4_Iter:1  loss: 2.81795 || 1:0.0032 | 2:0.1569 | 4:0.0219 ||
2019-12-18 16:02:11 ===> Epoch: 4_Iter:2  loss: 2.61381 || 1:0.0509 | 2:0.2772 | 4:0.0581 ||
2019-12-18 16:02:11 ===> Epoch: 4_Iter:3  loss: 2.69345 || 1:0.0602 | 2:0.2264 | 4:0.0199 ||
2019-12-18 16:02:12 ===> Epoch: 4_Iter:4  loss: 2.71766 || 1:0.0366 | 2:0.2297 | 4:0.0161 ||
2019-12-18 16:02:13 ===> Epoch: 4_Iter:5  loss: 2.81679 || 1:0.0486 | 2:0.1224 | 4:0.0122 ||
2019-12-18 16:02:13 ===> Epoch: 4_Iter:6  loss: 2.74164 || 1:0.0120 | 2:0.2267 | 4:0.0197 ||
2019-12-18 16:02:14 ===> Epoch: 4_Iter:7  loss: 2.76656 || 1:0.0139 | 2:0.2020 | 4:0.0175 ||
2019-12-18 16:02:55 ===> Epoch: 4_Iter:8  loss: 2.73591 || 1:0.0269 | 2:0.2129 | 4:0.0243 ||
2019-12-18 16:02:56 ===> Epoch: 4_Iter:9  loss: 2.72723 || 1:0.1122 | 2:0.1328 | 4:0.0278 ||
2019-12-18 16:02:56 ===> Epoch: 4_Iter:10  loss: 2.74154 || 1:0.0188 | 2:0.2064 | 4:0.0332 ||
2019-12-18 16:02:57 ===> Epoch: 4_Iter:11  loss: 2.87850 || 1:0.0278 | 2:0.0800 | 4:0.0137 ||
2019-12-18 16:02:58 ===> Epoch: 4_Iter:12  loss: 2.68402 || 1:0.1346 | 2:0.1660 | 4:0.0153 ||
2019-12-18 16:02:58 ===> Epoch: 4_Iter:13  loss: 2.88611 || 1:0.0504 | 2:0.0539 | 4:0.0096 ||
2019-12-18 16:02:59 ===> Epoch: 4_Iter:14  loss: 2.75080 || 1:0.0639 | 2:0.1752 | 4:0.0101 ||
2019-12-18 16:03:00 ===> Epoch: 4_Iter:15  loss: 2.76851 || 1:0.1006 | 2:0.1273 | 4:0.0036 ||
2019-12-18 16:03:39 ===> Epoch: 4_Iter:16  loss: 2.72127 || 1:0.0355 | 2:0.2019 | 4:0.0413 ||
2019-12-18 16:03:40 ===> Epoch: 4_Iter:17  loss: 2.79757 || 1:0.0020 | 2:0.1940 | 4:0.0064 ||
2019-12-18 16:03:40 ===> Epoch: 4_Iter:18  loss: 2.81358 || 1:0.0433 | 2:0.1208 | 4:0.0223 ||
2019-12-18 16:03:41 ===> Epoch: 4_Iter:19  loss: 2.71353 || 1:0.1163 | 2:0.1338 | 4:0.0363 ||
2019-12-18 16:03:42 ===> Current epoch time consumption: 2.32 minutes!
2019-12-18 16:03:42 ===> Estimated remaining training time: 19.13 hours!
2019-12-18 16:04:29 ===> Epoch: 5_Iter:0  loss: 2.95360 || 1:0.0010 | 2:0.0423 | 4:0.0031 ||
2019-12-18 16:04:30 ===> Epoch: 5_Iter:1  loss: 2.74855 || 1:0.0714 | 2:0.1694 | 4:0.0107 ||
2019-12-18 16:04:31 ===> Epoch: 5_Iter:2  loss: 2.74033 || 1:0.0037 | 2:0.2178 | 4:0.0381 ||
2019-12-18 16:04:32 ===> Epoch: 5_Iter:3  loss: 2.81582 || 1:0.1125 | 2:0.0601 | 4:0.0116 ||
2019-12-18 16:04:32 ===> Epoch: 5_Iter:4  loss: 2.73625 || 1:0.1365 | 2:0.1176 | 4:0.0096 ||
2019-12-18 16:04:33 ===> Epoch: 5_Iter:5  loss: 2.72928 || 1:0.0835 | 2:0.1715 | 4:0.0157 ||
2019-12-18 16:04:34 ===> Epoch: 5_Iter:6  loss: 2.84228 || 1:0.0361 | 2:0.1012 | 4:0.0205 ||
2019-12-18 16:04:35 ===> Epoch: 5_Iter:7  loss: 2.84380 || 1:0.0338 | 2:0.0996 | 4:0.0228 ||
2019-12-18 16:05:13 ===> Epoch: 5_Iter:8  loss: 2.62152 || 1:0.1349 | 2:0.2258 | 4:0.0177 ||
2019-12-18 16:05:14 ===> Epoch: 5_Iter:9  loss: 2.74689 || 1:0.0263 | 2:0.1762 | 4:0.0506 ||
2019-12-18 16:05:17 ===> Epoch: 5_Iter:10  loss: 2.73397 || 1:0.0257 | 2:0.1948 | 4:0.0455 ||
2019-12-18 16:05:18 ===> Epoch: 5_Iter:11  loss: 2.79171 || 1:0.0113 | 2:0.1620 | 4:0.0351 ||
2019-12-18 16:05:18 ===> Epoch: 5_Iter:12  loss: 2.80059 || 1:0.0044 | 2:0.1850 | 4:0.0101 ||
2019-12-18 16:05:19 ===> Epoch: 5_Iter:13  loss: 2.86357 || 1:0.0251 | 2:0.0955 | 4:0.0159 ||
2019-12-18 16:05:20 ===> Epoch: 5_Iter:14  loss: 2.58450 || 1:0.0564 | 2:0.3378 | 4:0.0214 ||
2019-12-18 16:05:20 ===> Epoch: 5_Iter:15  loss: 2.81613 || 1:0.0803 | 2:0.0929 | 4:0.0107 ||
2019-12-18 16:05:57 ===> Epoch: 5_Iter:16  loss: 2.92763 || 1:0.0011 | 2:0.0584 | 4:0.0128 ||
2019-12-18 16:06:00 ===> Epoch: 5_Iter:17  loss: 2.64017 || 1:0.0437 | 2:0.2806 | 4:0.0355 ||
2019-12-18 16:06:01 ===> Epoch: 5_Iter:18  loss: 2.71495 || 1:0.0539 | 2:0.2179 | 4:0.0133 ||
2019-12-18 16:06:02 ===> Epoch: 5_Iter:19  loss: 2.70147 || 1:0.0438 | 2:0.2369 | 4:0.0179 ||
2019-12-18 16:06:02 ===> Current epoch time consumption: 2.34 minutes!
2019-12-18 16:06:02 ===> Estimated remaining training time: 19.30 hours!
2019-12-18 16:06:50 ===> Epoch: 6_Iter:0  loss: 2.75282 || 1:0.0105 | 2:0.2270 | 4:0.0097 ||
2019-12-18 16:06:51 ===> Epoch: 6_Iter:1  loss: 2.71408 || 1:0.0405 | 2:0.2085 | 4:0.0368 ||
2019-12-18 16:06:52 ===> Epoch: 6_Iter:2  loss: 2.68022 || 1:0.1254 | 2:0.1713 | 4:0.0231 ||
2019-12-18 16:06:52 ===> Epoch: 6_Iter:3  loss: 2.83162 || 1:0.0059 | 2:0.1303 | 4:0.0321 ||
2019-12-18 16:06:53 ===> Epoch: 6_Iter:4  loss: 2.83850 || 1:0.0597 | 2:0.0996 | 4:0.0022 ||
2019-12-18 16:06:54 ===> Epoch: 6_Iter:5  loss: 2.69789 || 1:0.0922 | 2:0.1740 | 4:0.0359 ||
2019-12-18 16:06:54 ===> Epoch: 6_Iter:6  loss: 2.81652 || 1:0.0261 | 2:0.1372 | 4:0.0201 ||
2019-12-18 16:06:55 ===> Epoch: 6_Iter:7  loss: 2.83143 || 1:0.0259 | 2:0.1318 | 4:0.0109 ||
2019-12-18 16:07:35 ===> Epoch: 6_Iter:8  loss: 2.74042 || 1:0.0631 | 2:0.1868 | 4:0.0097 ||
2019-12-18 16:07:35 ===> Epoch: 6_Iter:9  loss: 2.79287 || 1:0.0572 | 2:0.1499 | 4:0.0000 ||
2019-12-18 16:07:36 ===> Epoch: 6_Iter:10  loss: 2.82767 || 1:0.0086 | 2:0.1528 | 4:0.0110 ||
2019-12-18 16:07:37 ===> Epoch: 6_Iter:11  loss: 2.75681 || 1:0.0412 | 2:0.1857 | 4:0.0162 ||
2019-12-18 16:07:37 ===> Epoch: 6_Iter:12  loss: 2.85926 || 1:0.0348 | 2:0.0864 | 4:0.0196 ||
2019-12-18 16:07:38 ===> Epoch: 6_Iter:13  loss: 2.88695 || 1:0.0057 | 2:0.1032 | 4:0.0041 ||
2019-12-18 16:07:39 ===> Epoch: 6_Iter:14  loss: 2.82382 || 1:0.0448 | 2:0.1293 | 4:0.0021 ||
2019-12-18 16:07:39 ===> Epoch: 6_Iter:15  loss: 2.73444 || 1:0.0686 | 2:0.1859 | 4:0.0110 ||
2019-12-18 16:08:18 ===> Epoch: 6_Iter:16  loss: 2.73274 || 1:0.1289 | 2:0.1240 | 4:0.0143 ||
2019-12-18 16:08:18 ===> Epoch: 6_Iter:17  loss: 2.74897 || 1:0.0104 | 2:0.2164 | 4:0.0242 ||
2019-12-18 16:08:19 ===> Epoch: 6_Iter:18  loss: 2.79907 || 1:0.0041 | 2:0.1756 | 4:0.0212 ||
2019-12-18 16:08:20 ===> Epoch: 6_Iter:19  loss: 2.75158 || 1:0.0112 | 2:0.2237 | 4:0.0135 ||
2019-12-18 16:08:21 ===> Current epoch time consumption: 2.31 minutes!
2019-12-18 16:08:21 ===> Estimated remaining training time: 18.95 hours!
2019-12-18 16:09:09 ===> Epoch: 7_Iter:0  loss: 2.81611 || 1:0.0548 | 2:0.0994 | 4:0.0297 ||
2019-12-18 16:09:10 ===> Epoch: 7_Iter:1  loss: 2.65761 || 1:0.0350 | 2:0.2532 | 4:0.0542 ||
2019-12-18 16:09:11 ===> Epoch: 7_Iter:2  loss: 2.88741 || 1:0.0234 | 2:0.0805 | 4:0.0087 ||
2019-12-18 16:09:11 ===> Epoch: 7_Iter:3  loss: 2.86954 || 1:0.0341 | 2:0.0935 | 4:0.0028 ||
2019-12-18 16:09:12 ===> Epoch: 7_Iter:4  loss: 2.73879 || 1:0.1011 | 2:0.1295 | 4:0.0306 ||
2019-12-18 16:09:13 ===> Epoch: 7_Iter:5  loss: 2.85873 || 1:0.0081 | 2:0.1058 | 4:0.0273 ||
2019-12-18 16:09:13 ===> Epoch: 7_Iter:6  loss: 2.82203 || 1:0.0799 | 2:0.0911 | 4:0.0070 ||
2019-12-18 16:09:14 ===> Epoch: 7_Iter:7  loss: 2.75026 || 1:0.0354 | 2:0.1809 | 4:0.0334 ||
2019-12-18 16:09:54 ===> Epoch: 7_Iter:8  loss: 2.79302 || 1:0.0383 | 2:0.1590 | 4:0.0097 ||
2019-12-18 16:09:54 ===> Epoch: 7_Iter:9  loss: 2.68191 || 1:0.1103 | 2:0.1858 | 4:0.0220 ||
2019-12-18 16:09:55 ===> Epoch: 7_Iter:10  loss: 2.71785 || 1:0.1050 | 2:0.1674 | 4:0.0097 ||
2019-12-18 16:09:56 ===> Epoch: 7_Iter:11  loss: 2.89842 || 1:0.0087 | 2:0.0834 | 4:0.0095 ||
2019-12-18 16:09:56 ===> Epoch: 7_Iter:12  loss: 2.62452 || 1:0.0206 | 2:0.3181 | 4:0.0368 ||
2019-12-18 16:09:57 ===> Epoch: 7_Iter:13  loss: 2.66475 || 1:0.0648 | 2:0.2643 | 4:0.0061 ||
2019-12-18 16:09:58 ===> Epoch: 7_Iter:14  loss: 2.86412 || 1:0.0107 | 2:0.1073 | 4:0.0178 ||
2019-12-18 16:09:58 ===> Epoch: 7_Iter:15  loss: 2.79028 || 1:0.0031 | 2:0.1943 | 4:0.0123 ||
2019-12-18 16:10:37 ===> Epoch: 7_Iter:16  loss: 2.63169 || 1:0.0368 | 2:0.2712 | 4:0.0603 ||
2019-12-18 16:10:38 ===> Epoch: 7_Iter:17  loss: 2.68540 || 1:0.0059 | 2:0.2940 | 4:0.0147 ||
2019-12-18 16:10:39 ===> Epoch: 7_Iter:18  loss: 2.78905 || 1:0.0991 | 2:0.1118 | 4:0.0000 ||
2019-12-18 16:10:40 ===> Epoch: 7_Iter:19  loss: 2.61851 || 1:0.0658 | 2:0.2751 | 4:0.0406 ||
2019-12-18 16:10:41 ===> Current epoch time consumption: 2.33 minutes!
2019-12-18 16:10:41 ===> Estimated remaining training time: 19.11 hours!
2019-12-18 16:11:28 ===> Epoch: 8_Iter:0  loss: 2.72384 || 1:0.0584 | 2:0.2130 | 4:0.0048 ||
2019-12-18 16:11:29 ===> Epoch: 8_Iter:1  loss: 2.79560 || 1:0.0298 | 2:0.1369 | 4:0.0377 ||
2019-12-18 16:11:29 ===> Epoch: 8_Iter:2  loss: 2.75384 || 1:0.0532 | 2:0.1911 | 4:0.0019 ||
2019-12-18 16:11:30 ===> Epoch: 8_Iter:3  loss: 2.86000 || 1:0.0407 | 2:0.0943 | 4:0.0050 ||
2019-12-18 16:11:31 ===> Epoch: 8_Iter:4  loss: 2.87119 || 1:0.0152 | 2:0.1105 | 4:0.0031 ||
2019-12-18 16:11:31 ===> Epoch: 8_Iter:5  loss: 2.79793 || 1:0.0084 | 2:0.1484 | 4:0.0452 ||
2019-12-18 16:11:32 ===> Epoch: 8_Iter:6  loss: 2.86424 || 1:0.0620 | 2:0.0620 | 4:0.0118 ||
2019-12-18 16:11:33 ===> Epoch: 8_Iter:7  loss: 2.74542 || 1:0.0218 | 2:0.2126 | 4:0.0203 ||
2019-12-18 16:12:38 ===> -------------------------------------------This is all configurations-----------------------------------------
2019-12-18 16:12:38 ===> opts:
user=zjf,
experiment=Unet_3D_,
data=2019-12-18,
warm=30,
root=/data1/zjf,
train_dir=MICCAI_BraTS_2019_Data_Training,
valid_dir=MICCAI_BraTS_2019_Data_Validation,
mode=train_all,
train_file=train_small.txt,
valid_file=valid_small.txt,
dataset=brats,
model=resnet,
model_name=Unet_3D,
model_depth=34,
input_C=4,
input_H=240,
input_W=240,
input_D=160,
output_D=155,
resnet_shortcut=A,
lr=0.001,
weight_decay=1e-05,
amsgrad=True,
criterion=softmax_dice,
num_class=4,
description=Unet_3d training on 128!,
seed=5,
no_cuda=False,
resume=checkpoint/DMFNet_T128_xavier_2019-11-19/model_epoch_139.pth,
load=False,
valid_transform=Compose([Pad((0, 0, 0, 5, 0)),NumpyType((np.float32, np.int64))]),
GPU=4, 5, 6, 7,
num_workers=8,
batch_size=4,
start_epoch=0,
end_epoch=500,
save_freq=50,
output_dir=output,
submission=submission,
visual=visualization,
test_date=2019-12-14,
test_file=model_epoch_last.pth,
snapshot=True,
use_TTA=False,
post_process=True,
save_format=nii,
crop_H=128,
crop_W=128,
crop_D=128
2019-12-18 16:12:38 ===> ---------------------------------------------This is a halving line-------------------------------------------
2019-12-18 16:12:38 ===> Unet_3d training on 128!
2019-12-18 16:12:44 ===> re-training!!!
2019-12-18 16:12:44 ===> Samples for train = 80
2019-12-18 16:18:08 ===> -------------------------------------------This is all configurations-----------------------------------------
2019-12-18 16:18:08 ===> opts:
user=zjf,
experiment=Unet_3D_,
data=2019-12-18,
warm=30,
root=/data1/zjf,
train_dir=MICCAI_BraTS_2019_Data_Training,
valid_dir=MICCAI_BraTS_2019_Data_Validation,
mode=train_all,
train_file=train_small.txt,
valid_file=valid_small.txt,
dataset=brats,
model=resnet,
model_name=Unet_3D,
model_depth=34,
input_C=4,
input_H=240,
input_W=240,
input_D=160,
output_D=155,
resnet_shortcut=A,
lr=0.001,
weight_decay=1e-05,
amsgrad=True,
criterion=softmax_dice,
num_class=4,
description=Unet_3d training on 128!,
seed=5,
no_cuda=False,
resume=checkpoint/DMFNet_T128_xavier_2019-11-19/model_epoch_139.pth,
load=False,
valid_transform=Compose([Pad((0, 0, 0, 5, 0)),NumpyType((np.float32, np.int64))]),
GPU=4, 5, 6, 7,
num_workers=8,
batch_size=4,
start_epoch=0,
end_epoch=500,
save_freq=50,
output_dir=output,
submission=submission,
visual=visualization,
test_date=2019-12-14,
test_file=model_epoch_last.pth,
snapshot=True,
use_TTA=False,
post_process=True,
save_format=nii,
crop_H=128,
crop_W=128,
crop_D=128
2019-12-18 16:18:08 ===> ---------------------------------------------This is a halving line-------------------------------------------
2019-12-18 16:18:08 ===> Unet_3d training on 128!
2019-12-18 16:18:14 ===> re-training!!!
2019-12-18 16:18:14 ===> Samples for train = 80
2019-12-18 16:23:09 ===> -------------------------------------------This is all configurations-----------------------------------------
2019-12-18 16:23:09 ===> opts:
user=zjf,
experiment=Unet_3D_,
data=2019-12-18,
warm=30,
root=/data1/zjf,
train_dir=MICCAI_BraTS_2019_Data_Training,
valid_dir=MICCAI_BraTS_2019_Data_Validation,
mode=train_all,
train_file=train_small.txt,
valid_file=valid_small.txt,
dataset=brats,
model=resnet,
model_name=Unet_3D,
model_depth=34,
input_C=4,
input_H=240,
input_W=240,
input_D=160,
output_D=155,
resnet_shortcut=A,
lr=0.001,
weight_decay=1e-05,
amsgrad=True,
criterion=softmax_dice,
num_class=4,
description=Unet_3d training on 128!,
seed=5,
no_cuda=False,
resume=checkpoint/DMFNet_T128_xavier_2019-11-19/model_epoch_139.pth,
load=False,
valid_transform=Compose([Pad((0, 0, 0, 5, 0)),NumpyType((np.float32, np.int64))]),
GPU=4, 5, 6, 7,
num_workers=8,
batch_size=4,
start_epoch=0,
end_epoch=500,
save_freq=50,
output_dir=output,
submission=submission,
visual=visualization,
test_date=2019-12-14,
test_file=model_epoch_last.pth,
snapshot=True,
use_TTA=False,
post_process=True,
save_format=nii,
crop_H=128,
crop_W=128,
crop_D=128
2019-12-18 16:23:09 ===> ---------------------------------------------This is a halving line-------------------------------------------
2019-12-18 16:23:09 ===> Unet_3d training on 128!
2019-12-18 16:23:14 ===> re-training!!!
2019-12-18 16:23:14 ===> Samples for train = 80
2019-12-18 16:26:50 ===> -------------------------------------------This is all configurations-----------------------------------------
2019-12-18 16:26:50 ===> opts:
user=zjf,
experiment=Unet_3D_,
data=2019-12-18,
warm=30,
root=/data1/zjf,
train_dir=MICCAI_BraTS_2019_Data_Training,
valid_dir=MICCAI_BraTS_2019_Data_Validation,
mode=train_all,
train_file=train_small.txt,
valid_file=valid_small.txt,
dataset=brats,
model=resnet,
model_name=Unet_3D,
model_depth=34,
input_C=4,
input_H=240,
input_W=240,
input_D=160,
output_D=155,
resnet_shortcut=A,
lr=0.001,
weight_decay=1e-05,
amsgrad=True,
criterion=softmax_dice,
num_class=4,
description=Unet_3d training on 128!,
seed=5,
no_cuda=False,
resume=checkpoint/DMFNet_T128_xavier_2019-11-19/model_epoch_139.pth,
load=False,
valid_transform=Compose([Pad((0, 0, 0, 5, 0)),NumpyType((np.float32, np.int64))]),
GPU=4, 5, 6, 7,
num_workers=8,
batch_size=4,
start_epoch=0,
end_epoch=500,
save_freq=50,
output_dir=output,
submission=submission,
visual=visualization,
test_date=2019-12-14,
test_file=model_epoch_last.pth,
snapshot=True,
use_TTA=False,
post_process=True,
save_format=nii,
crop_H=128,
crop_W=128,
crop_D=128
2019-12-18 16:26:50 ===> ---------------------------------------------This is a halving line-------------------------------------------
2019-12-18 16:26:50 ===> Unet_3d training on 128!
2019-12-18 16:26:56 ===> re-training!!!
2019-12-18 16:26:56 ===> Samples for train = 80
2019-12-18 16:30:07 ===> -------------------------------------------This is all configurations-----------------------------------------
2019-12-18 16:30:07 ===> opts:
user=zjf,
experiment=Unet_3D_,
data=2019-12-18,
warm=30,
root=/data1/zjf,
train_dir=MICCAI_BraTS_2019_Data_Training,
valid_dir=MICCAI_BraTS_2019_Data_Validation,
mode=train_all,
train_file=train_small.txt,
valid_file=valid_small.txt,
dataset=brats,
model=resnet,
model_name=Unet_3D,
model_depth=34,
input_C=4,
input_H=240,
input_W=240,
input_D=160,
output_D=155,
resnet_shortcut=A,
lr=0.001,
weight_decay=1e-05,
amsgrad=True,
criterion=softmax_dice,
num_class=4,
description=Unet_3d training on 128!,
seed=5,
no_cuda=False,
resume=checkpoint/DMFNet_T128_xavier_2019-11-19/model_epoch_139.pth,
load=False,
valid_transform=Compose([Pad((0, 0, 0, 5, 0)),NumpyType((np.float32, np.int64))]),
GPU=4, 5, 6, 7,
num_workers=8,
batch_size=4,
start_epoch=0,
end_epoch=500,
save_freq=50,
output_dir=output,
submission=submission,
visual=visualization,
test_date=2019-12-14,
test_file=model_epoch_last.pth,
snapshot=True,
use_TTA=False,
post_process=True,
save_format=nii,
crop_H=128,
crop_W=128,
crop_D=128
2019-12-18 16:30:07 ===> ---------------------------------------------This is a halving line-------------------------------------------
2019-12-18 16:30:07 ===> Unet_3d training on 128!
2019-12-18 16:30:12 ===> re-training!!!
2019-12-18 16:30:12 ===> Samples for train = 80
2019-12-18 16:32:53 ===> -------------------------------------------This is all configurations-----------------------------------------
2019-12-18 16:32:53 ===> opts:
user=zjf,
experiment=Unet_3D_,
data=2019-12-18,
warm=30,
root=/data1/zjf,
train_dir=MICCAI_BraTS_2019_Data_Training,
valid_dir=MICCAI_BraTS_2019_Data_Validation,
mode=train_all,
train_file=train_small.txt,
valid_file=valid_small.txt,
dataset=brats,
model=resnet,
model_name=Unet_3D,
model_depth=34,
input_C=4,
input_H=240,
input_W=240,
input_D=160,
output_D=155,
resnet_shortcut=A,
lr=0.001,
weight_decay=1e-05,
amsgrad=True,
criterion=softmax_dice,
num_class=4,
description=Unet_3d training on 128!,
seed=5,
no_cuda=False,
resume=checkpoint/DMFNet_T128_xavier_2019-11-19/model_epoch_139.pth,
load=False,
valid_transform=Compose([Pad((0, 0, 0, 5, 0)),NumpyType((np.float32, np.int64))]),
GPU=4, 5, 6, 7,
num_workers=8,
batch_size=4,
start_epoch=0,
end_epoch=500,
save_freq=50,
output_dir=output,
submission=submission,
visual=visualization,
test_date=2019-12-14,
test_file=model_epoch_last.pth,
snapshot=True,
use_TTA=False,
post_process=True,
save_format=nii,
crop_H=128,
crop_W=128,
crop_D=128
2019-12-18 16:32:53 ===> ---------------------------------------------This is a halving line-------------------------------------------
2019-12-18 16:32:53 ===> Unet_3d training on 128!
2019-12-18 16:32:58 ===> re-training!!!
2019-12-18 16:32:58 ===> Samples for train = 80
2019-12-18 16:36:16 ===> -------------------------------------------This is all configurations-----------------------------------------
2019-12-18 16:36:16 ===> opts:
user=zjf,
experiment=Unet_3D_,
data=2019-12-18,
warm=30,
root=/data1/zjf,
train_dir=MICCAI_BraTS_2019_Data_Training,
valid_dir=MICCAI_BraTS_2019_Data_Validation,
mode=train_all,
train_file=train_small.txt,
valid_file=valid_small.txt,
dataset=brats,
model=resnet,
model_name=Unet_3D,
model_depth=34,
input_C=4,
input_H=240,
input_W=240,
input_D=160,
output_D=155,
resnet_shortcut=A,
lr=0.001,
weight_decay=1e-05,
amsgrad=True,
criterion=softmax_dice,
num_class=4,
description=Unet_3d training on 128!,
seed=5,
no_cuda=False,
resume=checkpoint/DMFNet_T128_xavier_2019-11-19/model_epoch_139.pth,
load=False,
valid_transform=Compose([Pad((0, 0, 0, 5, 0)),NumpyType((np.float32, np.int64))]),
GPU=4, 5, 6, 7,
num_workers=8,
batch_size=4,
start_epoch=0,
end_epoch=500,
save_freq=50,
output_dir=output,
submission=submission,
visual=visualization,
test_date=2019-12-14,
test_file=model_epoch_last.pth,
snapshot=True,
use_TTA=False,
post_process=True,
save_format=nii,
crop_H=128,
crop_W=128,
crop_D=128
2019-12-18 16:36:16 ===> ---------------------------------------------This is a halving line-------------------------------------------
2019-12-18 16:36:16 ===> Unet_3d training on 128!
2019-12-18 16:36:21 ===> re-training!!!
2019-12-18 16:36:21 ===> Samples for train = 80
