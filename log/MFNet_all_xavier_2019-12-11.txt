2019-12-11 21:44:47 ===> -------------------------------------------This is all configurations-----------------------------------------
2019-12-11 21:44:47 ===> opts:
user=zjf,
experiment=MFNet_all_xavier_,
data=2019-12-11,
warm=30,
root=/data1/zjf,
train_dir=MICCAI_BraTS_2019_Data_Training,
valid_dir=MICCAI_BraTS_2019_Data_Training,
mode=train_all,
train_file=all.txt,
valid_file=valid_small.txt,
dataset=brats,
model=resnet,
model_name=MFNet,
model_depth=34,
input_C=4,
input_H=240,
input_W=240,
input_D=160,
output_D=155,
resnet_shortcut=A,
lr=0.001,
weight_decay=1e-05,
amsgrad=True,
criterion=Generalized_dice,
num_class=4,
description=mfnet with adaptive sft in 2,3,4 stage and training on 128!,
seed=5,
no_cuda=False,
resume=checkpoint/DMFNet_T128_xavier_2019-11-19/model_epoch_139.pth,
load=False,
valid_transform=Compose([Pad((0, 0, 0, 5, 0)),NumpyType((np.float32, np.int64))]),
GPU=4, 5, 6, 7,
num_workers=8,
batch_size=4,
start_epoch=0,
end_epoch=500,
save_freq=50,
output_dir=output,
submission=submission,
visual=visualization,
test_date=2019-12-10,
test_file=model_epoch_last.pth,
snapshot=True,
use_TTA=False,
post_process=True,
save_format=nii,
crop_H=128,
crop_W=128,
crop_D=128
2019-12-11 21:44:47 ===> ---------------------------------------------This is a halving line-------------------------------------------
2019-12-11 21:44:47 ===> mfnet with adaptive sft in 2,3,4 stage and training on 128!
2019-12-11 21:44:52 ===> re-training!!!
2019-12-11 21:44:52 ===> Samples for train = 335
2019-12-11 21:46:20 ===> Epoch: 0_Iter:0  loss: 0.98557 || 1:0.0296 | 2:0.0161 | 4:0.0048 ||
2019-12-11 21:46:25 ===> Epoch: 0_Iter:1  loss: 0.95623 || 1:0.0793 | 2:0.0046 | 4:0.0035 ||
2019-12-11 21:46:25 ===> Epoch: 0_Iter:2  loss: 0.94905 || 1:0.0557 | 2:0.0039 | 4:0.0348 ||
2019-12-11 21:46:26 ===> Epoch: 0_Iter:3  loss: 0.96598 || 1:0.0459 | 2:0.0009 | 4:0.0279 ||
2019-12-11 21:46:26 ===> Epoch: 0_Iter:4  loss: 0.95020 || 1:0.0600 | 2:0.0060 | 4:0.0306 ||
2019-12-11 21:46:26 ===> Epoch: 0_Iter:5  loss: 0.89511 || 1:0.1694 | 2:0.0084 | 4:0.2914 ||
2019-12-11 21:46:27 ===> Epoch: 0_Iter:6  loss: 0.95463 || 1:0.0223 | 2:0.0209 | 4:0.2792 ||
2019-12-11 21:46:27 ===> Epoch: 0_Iter:7  loss: 0.83440 || 1:0.2081 | 2:0.0414 | 4:0.1698 ||
2019-12-11 21:47:03 ===> Epoch: 0_Iter:8  loss: 0.93303 || 1:0.0493 | 2:0.0099 | 4:0.2410 ||
2019-12-11 21:47:03 ===> Epoch: 0_Iter:9  loss: 0.76355 || 1:0.2265 | 2:0.0640 | 4:0.3477 ||
2019-12-11 21:47:07 ===> Epoch: 0_Iter:10  loss: 0.77766 || 1:0.5354 | 2:0.0960 | 4:0.2279 ||
2019-12-11 21:47:07 ===> Epoch: 0_Iter:11  loss: 0.70165 || 1:0.3899 | 2:0.2212 | 4:0.4013 ||
2019-12-11 21:47:08 ===> Epoch: 0_Iter:12  loss: 0.88466 || 1:0.0518 | 2:0.1020 | 4:0.5527 ||
2019-12-11 21:47:08 ===> Epoch: 0_Iter:13  loss: 0.62916 || 1:0.3500 | 2:0.2383 | 4:0.5003 ||
2019-12-11 21:47:09 ===> Epoch: 0_Iter:14  loss: 0.60468 || 1:0.3152 | 2:0.2063 | 4:0.5548 ||
2019-12-11 21:47:09 ===> Epoch: 0_Iter:15  loss: 0.68946 || 1:0.3242 | 2:0.1194 | 4:0.4997 ||
2019-12-11 21:48:03 ===> Epoch: 0_Iter:16  loss: 0.58258 || 1:0.2506 | 2:0.3263 | 4:0.5494 ||
2019-12-11 21:48:04 ===> Epoch: 0_Iter:17  loss: 0.70338 || 1:0.2192 | 2:0.3998 | 4:0.5354 ||
2019-12-11 21:48:04 ===> Epoch: 0_Iter:18  loss: 0.86221 || 1:0.2496 | 2:0.2390 | 4:0.1311 ||
2019-12-11 21:48:04 ===> Epoch: 0_Iter:19  loss: 0.59475 || 1:0.3223 | 2:0.3707 | 4:0.5980 ||
2019-12-11 21:48:05 ===> Epoch: 0_Iter:20  loss: 0.60645 || 1:0.2078 | 2:0.3792 | 4:0.6687 ||
2019-12-11 21:48:08 ===> Epoch: 0_Iter:21  loss: 0.64162 || 1:0.0862 | 2:0.5733 | 4:0.5720 ||
2019-12-11 21:48:09 ===> Epoch: 0_Iter:22  loss: 0.60331 || 1:0.1522 | 2:0.4958 | 4:0.7589 ||
2019-12-11 21:48:09 ===> Epoch: 0_Iter:23  loss: 0.68732 || 1:0.0777 | 2:0.2991 | 4:0.6437 ||
2019-12-11 21:48:54 ===> Epoch: 0_Iter:24  loss: 0.78343 || 1:0.0742 | 2:0.3195 | 4:0.2925 ||
2019-12-11 21:48:56 ===> Epoch: 0_Iter:25  loss: 0.65817 || 1:0.0464 | 2:0.4965 | 4:0.4245 ||
2019-12-11 21:48:59 ===> Epoch: 0_Iter:26  loss: 0.64656 || 1:0.0376 | 2:0.3068 | 4:0.4172 ||
2019-12-11 21:49:05 ===> Epoch: 0_Iter:27  loss: 0.60629 || 1:0.0018 | 2:0.6119 | 4:0.5026 ||
2019-12-11 21:49:05 ===> Epoch: 0_Iter:28  loss: 0.45749 || 1:0.0001 | 2:0.2388 | 4:0.6797 ||
2019-12-11 21:49:06 ===> Epoch: 0_Iter:29  loss: 0.70733 || 1:0.0001 | 2:0.2581 | 4:0.4011 ||
2019-12-11 21:49:06 ===> Epoch: 0_Iter:30  loss: 0.76251 || 1:0.0469 | 2:0.4942 | 4:0.5002 ||
2019-12-11 21:49:07 ===> Epoch: 0_Iter:31  loss: 0.61083 || 1:0.0041 | 2:0.5516 | 4:0.5395 ||
2019-12-11 21:49:46 ===> Epoch: 0_Iter:32  loss: 0.62381 || 1:0.0687 | 2:0.5651 | 4:0.6322 ||
2019-12-11 21:49:51 ===> Epoch: 0_Iter:33  loss: 0.62364 || 1:0.1369 | 2:0.5876 | 4:0.5166 ||
2019-12-11 21:49:53 ===> Epoch: 0_Iter:34  loss: 0.72012 || 1:0.1833 | 2:0.4525 | 4:0.3020 ||
2019-12-11 21:50:10 ===> Epoch: 0_Iter:35  loss: 0.55921 || 1:0.2819 | 2:0.4813 | 4:0.7224 ||
2019-12-11 21:50:11 ===> Epoch: 0_Iter:36  loss: 0.65945 || 1:0.2584 | 2:0.4835 | 4:0.3606 ||
2019-12-11 21:50:11 ===> Epoch: 0_Iter:37  loss: 0.70355 || 1:0.1680 | 2:0.5129 | 4:0.7655 ||
2019-12-11 21:50:11 ===> Epoch: 0_Iter:38  loss: 0.71397 || 1:0.0727 | 2:0.5847 | 4:0.5342 ||
2019-12-11 21:50:12 ===> Epoch: 0_Iter:39  loss: 0.67335 || 1:0.1694 | 2:0.2976 | 4:0.5307 ||
2019-12-11 21:50:45 ===> Epoch: 0_Iter:40  loss: 0.49254 || 1:0.1066 | 2:0.5012 | 4:0.6457 ||
2019-12-11 21:50:48 ===> Epoch: 0_Iter:41  loss: 0.56258 || 1:0.1167 | 2:0.5543 | 4:0.7217 ||
2019-12-11 21:50:50 ===> Epoch: 0_Iter:42  loss: 0.56878 || 1:0.1196 | 2:0.5805 | 4:0.5592 ||
2019-12-11 21:51:16 ===> Epoch: 0_Iter:43  loss: 0.51248 || 1:0.3110 | 2:0.6658 | 4:0.7169 ||
2019-12-11 21:51:16 ===> Epoch: 0_Iter:44  loss: 0.70308 || 1:0.1901 | 2:0.1918 | 4:0.6041 ||
2019-12-11 21:51:17 ===> Epoch: 0_Iter:45  loss: 0.52344 || 1:0.3721 | 2:0.4596 | 4:0.7098 ||
2019-12-11 21:51:17 ===> Epoch: 0_Iter:46  loss: 0.44832 || 1:0.2279 | 2:0.5992 | 4:0.7875 ||
2019-12-11 21:51:18 ===> Epoch: 0_Iter:47  loss: 0.87632 || 1:0.0110 | 2:0.3340 | 4:0.5099 ||
2019-12-11 21:51:45 ===> Epoch: 0_Iter:48  loss: 0.62362 || 1:0.2165 | 2:0.3521 | 4:0.6384 ||
2019-12-11 21:51:45 ===> Epoch: 0_Iter:49  loss: 0.48058 || 1:0.4575 | 2:0.5093 | 4:0.6994 ||
2019-12-11 21:51:51 ===> Epoch: 0_Iter:50  loss: 0.77090 || 1:0.1021 | 2:0.4932 | 4:0.4588 ||
2019-12-11 21:52:20 ===> Epoch: 0_Iter:51  loss: 0.61823 || 1:0.2479 | 2:0.5221 | 4:0.6500 ||
2019-12-11 21:52:20 ===> Epoch: 0_Iter:52  loss: 0.51042 || 1:0.3894 | 2:0.4580 | 4:0.6184 ||
2019-12-11 21:52:21 ===> Epoch: 0_Iter:53  loss: 0.64405 || 1:0.1288 | 2:0.6065 | 4:0.7395 ||
2019-12-11 21:52:21 ===> Epoch: 0_Iter:54  loss: 0.50749 || 1:0.4032 | 2:0.6736 | 4:0.7739 ||
2019-12-11 21:52:22 ===> Epoch: 0_Iter:55  loss: 0.41421 || 1:0.0968 | 2:0.5463 | 4:0.7221 ||
2019-12-11 21:52:38 ===> Epoch: 0_Iter:56  loss: 0.68535 || 1:0.0309 | 2:0.3710 | 4:0.6074 ||
2019-12-11 21:52:38 ===> Epoch: 0_Iter:57  loss: 0.50533 || 1:0.0024 | 2:0.5189 | 4:0.5163 ||
2019-12-11 21:52:48 ===> Epoch: 0_Iter:58  loss: 0.64166 || 1:0.0683 | 2:0.3878 | 4:0.6624 ||
2019-12-11 21:53:19 ===> Epoch: 0_Iter:59  loss: 0.46378 || 1:0.0933 | 2:0.6734 | 4:0.7370 ||
2019-12-11 21:53:19 ===> Epoch: 0_Iter:60  loss: 0.54592 || 1:0.1462 | 2:0.6070 | 4:0.6612 ||
2019-12-11 21:53:20 ===> Epoch: 0_Iter:61  loss: 0.49495 || 1:0.1022 | 2:0.6701 | 4:0.6713 ||
2019-12-11 21:53:20 ===> Epoch: 0_Iter:62  loss: 0.53446 || 1:0.1376 | 2:0.6153 | 4:0.7567 ||
2019-12-11 21:53:20 ===> Epoch: 0_Iter:63  loss: 0.49947 || 1:0.2749 | 2:0.4977 | 4:0.7246 ||
2019-12-11 21:53:33 ===> Epoch: 0_Iter:64  loss: 0.54074 || 1:0.2005 | 2:0.6641 | 4:0.7365 ||
2019-12-11 21:53:34 ===> Epoch: 0_Iter:65  loss: 0.51351 || 1:0.0681 | 2:0.6158 | 4:0.6484 ||
2019-12-11 21:53:42 ===> Epoch: 0_Iter:66  loss: 0.49373 || 1:0.4633 | 2:0.4730 | 4:0.5519 ||
2019-12-11 21:54:19 ===> Epoch: 0_Iter:67  loss: 0.49137 || 1:0.5713 | 2:0.6081 | 4:0.5307 ||
2019-12-11 21:54:20 ===> Epoch: 0_Iter:68  loss: 0.50735 || 1:0.3916 | 2:0.7009 | 4:0.7918 ||
2019-12-11 21:54:20 ===> Epoch: 0_Iter:69  loss: 0.42007 || 1:0.5597 | 2:0.7509 | 4:0.6273 ||
2019-12-11 21:54:21 ===> Epoch: 0_Iter:70  loss: 0.39854 || 1:0.7029 | 2:0.7082 | 4:0.8479 ||
2019-12-11 21:54:21 ===> Epoch: 0_Iter:71  loss: 0.37159 || 1:0.7381 | 2:0.7219 | 4:0.6848 ||
2019-12-11 21:54:27 ===> Epoch: 0_Iter:72  loss: 0.36081 || 1:0.6388 | 2:0.7024 | 4:0.7441 ||
2019-12-11 21:54:27 ===> Epoch: 0_Iter:73  loss: 0.58590 || 1:0.1570 | 2:0.6533 | 4:0.6931 ||
2019-12-11 21:54:40 ===> Epoch: 0_Iter:74  loss: 0.59619 || 1:0.5834 | 2:0.4910 | 4:0.3986 ||
2019-12-11 21:55:19 ===> Epoch: 0_Iter:75  loss: 0.67024 || 1:0.1390 | 2:0.4757 | 4:0.6548 ||
2019-12-11 21:55:20 ===> Epoch: 0_Iter:76  loss: 0.41359 || 1:0.2676 | 2:0.4975 | 4:0.7459 ||
2019-12-11 21:55:20 ===> Epoch: 0_Iter:77  loss: 0.53020 || 1:0.2853 | 2:0.6112 | 4:0.6067 ||
2019-12-11 21:55:21 ===> Epoch: 0_Iter:78  loss: 0.57070 || 1:0.2364 | 2:0.6002 | 4:0.6472 ||
2019-12-11 21:55:21 ===> Epoch: 0_Iter:79  loss: 0.30607 || 1:0.6254 | 2:0.7194 | 4:0.8197 ||
2019-12-11 21:55:22 ===> Epoch: 0_Iter:80  loss: 0.59169 || 1:0.2308 | 2:0.5100 | 4:0.5826 ||
2019-12-11 21:55:22 ===> Epoch: 0_Iter:81  loss: 0.41577 || 1:0.3902 | 2:0.6034 | 4:0.6373 ||
2019-12-11 21:55:32 ===> Epoch: 0_Iter:82  loss: 0.41494 || 1:0.7267 | 2:0.4233 | 4:0.7330 ||
2019-12-11 21:56:00 ===> Epoch: 0_Iter:83  loss: 0.37244 || 1:0.5210 | 2:0.6182 | 4:0.7769 ||
2019-12-11 21:56:01 ===> Current epoch time consumption: 11.14 minutes!
2019-12-11 21:56:01 ===> Estimated remaining training time: 92.65 hours!
2019-12-11 21:57:07 ===> Epoch: 1_Iter:0  loss: 0.78325 || 1:0.0498 | 2:0.3527 | 4:0.6532 ||
2019-12-11 21:57:08 ===> Epoch: 1_Iter:1  loss: 0.37621 || 1:0.4337 | 2:0.7165 | 4:0.7620 ||
2019-12-11 21:57:08 ===> Epoch: 1_Iter:2  loss: 0.55189 || 1:0.3225 | 2:0.7123 | 4:0.7883 ||
2019-12-11 21:57:09 ===> Epoch: 1_Iter:3  loss: 0.49281 || 1:0.3519 | 2:0.7116 | 4:0.5620 ||
2019-12-11 21:57:10 ===> Epoch: 1_Iter:4  loss: 0.28373 || 1:0.4502 | 2:0.5706 | 4:0.8297 ||
2019-12-11 21:57:10 ===> Epoch: 1_Iter:5  loss: 0.39383 || 1:0.2677 | 2:0.6326 | 4:0.7462 ||
2019-12-11 21:57:10 ===> Epoch: 1_Iter:6  loss: 0.48404 || 1:0.3892 | 2:0.6104 | 4:0.7705 ||
2019-12-11 21:57:11 ===> Epoch: 1_Iter:7  loss: 0.53287 || 1:0.0990 | 2:0.4279 | 4:0.4848 ||
2019-12-11 21:58:13 ===> Epoch: 1_Iter:8  loss: 0.70948 || 1:0.1383 | 2:0.4026 | 4:0.3423 ||
2019-12-11 21:58:14 ===> Epoch: 1_Iter:9  loss: 0.38873 || 1:0.2885 | 2:0.5268 | 4:0.6317 ||
2019-12-11 21:58:14 ===> Epoch: 1_Iter:10  loss: 0.99991 || 1:0.1984 | 2:0.2422 | 4:0.0000 ||
2019-12-11 21:58:15 ===> Epoch: 1_Iter:11  loss: 0.53968 || 1:0.5425 | 2:0.4138 | 4:0.6728 ||
2019-12-11 21:58:17 ===> Epoch: 1_Iter:12  loss: 0.64732 || 1:0.2858 | 2:0.5701 | 4:0.4519 ||
2019-12-11 21:58:18 ===> Epoch: 1_Iter:13  loss: 0.46862 || 1:0.3616 | 2:0.7013 | 4:0.6973 ||
2019-12-11 21:58:18 ===> Epoch: 1_Iter:14  loss: 0.68897 || 1:0.2353 | 2:0.5134 | 4:0.3891 ||
2019-12-11 21:58:18 ===> Epoch: 1_Iter:15  loss: 0.54570 || 1:0.2542 | 2:0.4984 | 4:0.5489 ||
2019-12-11 21:59:16 ===> Epoch: 1_Iter:16  loss: 0.47203 || 1:0.3713 | 2:0.6075 | 4:0.7139 ||
2019-12-11 21:59:17 ===> Epoch: 1_Iter:17  loss: 0.55410 || 1:0.4278 | 2:0.3904 | 4:0.4733 ||
2019-12-11 21:59:17 ===> Epoch: 1_Iter:18  loss: 0.55066 || 1:0.3497 | 2:0.4489 | 4:0.8346 ||
2019-12-11 21:59:17 ===> Epoch: 1_Iter:19  loss: 0.50697 || 1:0.4158 | 2:0.3923 | 4:0.5631 ||
2019-12-11 21:59:18 ===> Epoch: 1_Iter:20  loss: 0.57822 || 1:0.6308 | 2:0.3058 | 4:0.5151 ||
2019-12-11 21:59:19 ===> Epoch: 1_Iter:21  loss: 0.51088 || 1:0.4580 | 2:0.5215 | 4:0.7243 ||
2019-12-11 21:59:19 ===> Epoch: 1_Iter:22  loss: 0.68540 || 1:0.1989 | 2:0.2585 | 4:0.8296 ||
2019-12-11 21:59:20 ===> Epoch: 1_Iter:23  loss: 0.57403 || 1:0.1706 | 2:0.4951 | 4:0.6467 ||
2019-12-11 22:00:16 ===> Epoch: 1_Iter:24  loss: 0.55520 || 1:0.3779 | 2:0.7068 | 4:0.6721 ||
2019-12-11 22:00:16 ===> Epoch: 1_Iter:25  loss: 0.47869 || 1:0.4322 | 2:0.4639 | 4:0.8413 ||
2019-12-11 22:00:17 ===> Epoch: 1_Iter:26  loss: 0.53767 || 1:0.3017 | 2:0.6309 | 4:0.8376 ||
2019-12-11 22:00:17 ===> Epoch: 1_Iter:27  loss: 0.69745 || 1:0.3353 | 2:0.1760 | 4:0.6862 ||
2019-12-11 22:00:24 ===> Epoch: 1_Iter:28  loss: 0.52125 || 1:0.3233 | 2:0.6373 | 4:0.8189 ||
2019-12-11 22:00:25 ===> Epoch: 1_Iter:29  loss: 0.56723 || 1:0.1895 | 2:0.7034 | 4:0.8094 ||
2019-12-11 22:00:25 ===> Epoch: 1_Iter:30  loss: 0.87109 || 1:0.0575 | 2:0.2963 | 4:0.4495 ||
2019-12-11 22:00:26 ===> Epoch: 1_Iter:31  loss: 0.50965 || 1:0.4069 | 2:0.6714 | 4:0.7029 ||
